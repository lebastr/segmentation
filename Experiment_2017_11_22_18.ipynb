{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Учим VGG-Unet по 3-ем каналам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.5):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "KTF.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 12:14:56 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    76W / 149W |   5807MiB / 11439MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1784      G   /usr/lib/xorg/Xorg                            15MiB |\r\n",
      "|    0      3105      C   ...e/lebedev/anaconda2/envs/gpu/bin/python  5780MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import unet\n",
    "import dataset\n",
    "import train_test_loader\n",
    "import learning_experiment as lexperiment\n",
    "\n",
    "import datetime\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create experiment in directory: ./experiments/2017-11-22 12:15:04.074407\n"
     ]
    }
   ],
   "source": [
    "DESCRIPTION = u\"\"\"\n",
    "Учим VGG-Unet по 3м каналам RGB\n",
    "Experiment_2017_11_22_18\n",
    "\"\"\"\n",
    "experiment = lexperiment.create_experiment(DESCRIPTION, \n",
    "                               dataset.DataSet(\"./dataset/trainset\", [dataset.ChannelRGB_PanSharpen], image_size=(224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = experiment.data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = unet.VGGUnetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in net.vgg_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "net.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = lexperiment.BatchGenerator(data_set, data_set.train_ids, \n",
    "                                      random_rotate=True, \n",
    "                                      shuffle_on_each_epoch=True, \n",
    "                                      random_translate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, loss: 0.075703\n",
      "epoch: 21, loss: 0.121682\n",
      "epoch: 21, loss: 0.065386\n",
      "epoch: 21, loss: 0.071251\n",
      "epoch: 21, loss: 0.021198\n",
      "epoch: 21, loss: 0.062680\n",
      "epoch: 21, loss: 0.140637\n",
      "epoch: 21, loss: 0.058790\n",
      "epoch: 21, loss: 0.119574\n",
      "epoch: 21, loss: 0.065980\n",
      "epoch: 21, loss: 0.058642\n",
      "epoch: 21, loss: 0.073559\n",
      "epoch: 21, loss: 0.070963\n",
      "epoch: 21, loss: 0.017313\n",
      "epoch: 21, loss: 0.118583\n",
      "epoch: 21, loss: 0.048516\n",
      "epoch: 21, loss: 0.053832\n",
      "epoch: 21, loss: 0.104357\n",
      "epoch: 21, loss: 0.116548\n",
      "epoch: 21, loss: 0.107177\n",
      "epoch: 21, loss: 0.106339\n",
      "epoch: 21, loss: 0.097471\n",
      "epoch: 21, loss: 0.051775\n",
      "epoch: 21, loss: 0.108461\n",
      "epoch: 21, loss: 0.044569\n",
      "epoch: 21, loss: 0.036140\n",
      "epoch: 21, loss: 0.073114\n",
      "epoch: 21, loss: 0.087403\n",
      "epoch: 21, loss: 0.051514\n",
      "epoch: 21, loss: 0.053967\n",
      "epoch: 21, loss: 0.117114\n",
      "epoch: 21, loss: 0.087338\n",
      "epoch: 21, loss: 0.060981\n",
      "epoch: 21, loss: 0.078075\n",
      "epoch: 21, loss: 0.061350\n",
      "epoch: 21, loss: 0.028897\n",
      "epoch: 21, loss: 0.084303\n",
      "epoch: 21, loss: 0.099046\n",
      "epoch: 21, loss: 0.115052\n",
      "epoch: 21, loss: 0.055984\n",
      "epoch: 21, loss: 0.020296\n",
      "epoch: 21, loss: 0.122945\n",
      "epoch: 21, loss: 0.067596\n",
      "epoch: 21, loss: 0.102213\n",
      "epoch: 21, loss: 0.044358\n",
      "epoch: 21, loss: 0.068507\n",
      "epoch: 21, loss: 0.049069\n",
      "epoch: 21, loss: 0.037946\n",
      "epoch: 21, loss: 0.168347\n",
      "epoch: 21, loss: 0.090109\n",
      "epoch: 21, loss: 0.029062\n",
      "epoch: 21, loss: 0.066811\n",
      "epoch: 21, loss: 0.107938\n",
      "epoch: 21, loss: 0.081671\n",
      "epoch: 21, loss: 0.125708\n",
      "epoch: 21, loss: 0.044505\n",
      "epoch: 21, loss: 0.085806\n",
      "epoch: 21, loss: 0.012360\n",
      "epoch: 21, loss: 0.135135\n",
      "epoch: 21, loss: 0.114089\n",
      "epoch: 21, loss: 0.128359\n",
      "epoch: 21, loss: 0.139006\n",
      "epoch: 21, loss: 0.108474\n",
      "epoch: 21, loss: 0.050985\n",
      "epoch: 21, loss: 0.185756\n",
      "epoch: 22, loss: 0.068011\n",
      "epoch: 22, loss: 0.049054\n",
      "epoch: 22, loss: 0.148523\n",
      "epoch: 22, loss: 0.082033\n",
      "epoch: 22, loss: 0.090433\n",
      "epoch: 22, loss: 0.075352\n",
      "epoch: 22, loss: 0.080554\n",
      "epoch: 22, loss: 0.065859\n",
      "epoch: 22, loss: 0.092709\n",
      "epoch: 22, loss: 0.078321\n",
      "epoch: 22, loss: 0.056456\n",
      "epoch: 22, loss: 0.066895\n",
      "epoch: 22, loss: 0.132355\n",
      "epoch: 22, loss: 0.060097\n",
      "epoch: 22, loss: 0.062006\n",
      "epoch: 22, loss: 0.078931\n",
      "epoch: 22, loss: 0.128023\n",
      "epoch: 22, loss: 0.070470\n",
      "epoch: 22, loss: 0.109509\n",
      "epoch: 22, loss: 0.075278\n",
      "epoch: 22, loss: 0.125710\n",
      "epoch: 22, loss: 0.030272\n",
      "epoch: 22, loss: 0.106684\n",
      "epoch: 22, loss: 0.105590\n",
      "epoch: 22, loss: 0.034140\n",
      "epoch: 22, loss: 0.052231\n",
      "epoch: 22, loss: 0.114497\n",
      "epoch: 22, loss: 0.107686\n",
      "epoch: 22, loss: 0.045506\n",
      "epoch: 22, loss: 0.063422\n",
      "epoch: 22, loss: 0.073283\n",
      "epoch: 22, loss: 0.068688\n",
      "epoch: 22, loss: 0.108992\n",
      "epoch: 22, loss: 0.103287\n",
      "epoch: 22, loss: 0.077099\n",
      "epoch: 22, loss: 0.102742\n",
      "epoch: 22, loss: 0.028131\n",
      "epoch: 22, loss: 0.083934\n",
      "epoch: 22, loss: 0.096702\n",
      "epoch: 22, loss: 0.025049\n",
      "epoch: 22, loss: 0.133331\n",
      "epoch: 22, loss: 0.069273\n",
      "epoch: 22, loss: 0.115147\n",
      "epoch: 22, loss: 0.133297\n",
      "epoch: 22, loss: 0.033969\n",
      "epoch: 22, loss: 0.127600\n",
      "epoch: 22, loss: 0.086783\n",
      "epoch: 22, loss: 0.063730\n",
      "epoch: 22, loss: 0.044701\n",
      "epoch: 22, loss: 0.083527\n",
      "epoch: 22, loss: 0.101877\n",
      "epoch: 22, loss: 0.047315\n",
      "epoch: 22, loss: 0.072244\n",
      "epoch: 22, loss: 0.035935\n",
      "epoch: 22, loss: 0.069263\n",
      "epoch: 22, loss: 0.059654\n",
      "epoch: 22, loss: 0.102298\n",
      "epoch: 22, loss: 0.047371\n",
      "epoch: 22, loss: 0.054992\n",
      "epoch: 22, loss: 0.136854\n",
      "epoch: 22, loss: 0.093846\n",
      "epoch: 22, loss: 0.054187\n",
      "epoch: 22, loss: 0.064499\n",
      "epoch: 22, loss: 0.080555\n",
      "epoch: 22, loss: 0.061545\n",
      "epoch: 23, loss: 0.123601\n",
      "epoch: 23, loss: 0.092856\n",
      "epoch: 23, loss: 0.074147\n",
      "epoch: 23, loss: 0.089801\n",
      "epoch: 23, loss: 0.083705\n",
      "epoch: 23, loss: 0.083821\n",
      "epoch: 23, loss: 0.100155\n",
      "epoch: 23, loss: 0.075265\n",
      "epoch: 23, loss: 0.105614\n",
      "epoch: 23, loss: 0.108784\n",
      "epoch: 23, loss: 0.072271\n",
      "epoch: 23, loss: 0.032433\n",
      "epoch: 23, loss: 0.085693\n",
      "epoch: 23, loss: 0.057996\n",
      "epoch: 23, loss: 0.051714\n",
      "epoch: 23, loss: 0.019296\n",
      "epoch: 23, loss: 0.092468\n",
      "epoch: 23, loss: 0.071209\n",
      "epoch: 23, loss: 0.056455\n",
      "epoch: 23, loss: 0.088492\n",
      "epoch: 23, loss: 0.069117\n",
      "epoch: 23, loss: 0.126486\n",
      "epoch: 23, loss: 0.142491\n",
      "epoch: 23, loss: 0.052148\n",
      "epoch: 23, loss: 0.011279\n",
      "epoch: 23, loss: 0.098026\n",
      "epoch: 23, loss: 0.059360\n",
      "epoch: 23, loss: 0.040226\n",
      "epoch: 23, loss: 0.074478\n",
      "epoch: 23, loss: 0.114650\n",
      "epoch: 23, loss: 0.101822\n",
      "epoch: 23, loss: 0.049222\n",
      "epoch: 23, loss: 0.051663\n",
      "epoch: 23, loss: 0.059253\n",
      "epoch: 23, loss: 0.106453\n",
      "epoch: 23, loss: 0.177223\n",
      "epoch: 23, loss: 0.079327\n",
      "epoch: 23, loss: 0.101973\n",
      "epoch: 23, loss: 0.105412\n",
      "epoch: 23, loss: 0.092463\n",
      "epoch: 23, loss: 0.059602\n",
      "epoch: 23, loss: 0.086392\n",
      "epoch: 23, loss: 0.033835\n",
      "epoch: 23, loss: 0.029431\n",
      "epoch: 23, loss: 0.044737\n",
      "epoch: 23, loss: 0.074964\n",
      "epoch: 23, loss: 0.069329\n",
      "epoch: 23, loss: 0.102896\n",
      "epoch: 23, loss: 0.052947\n",
      "epoch: 23, loss: 0.089763\n",
      "epoch: 23, loss: 0.152754\n",
      "epoch: 23, loss: 0.094760\n",
      "epoch: 23, loss: 0.071929\n",
      "epoch: 23, loss: 0.076812\n",
      "epoch: 23, loss: 0.078670\n",
      "epoch: 23, loss: 0.040799\n",
      "epoch: 23, loss: 0.125451\n",
      "epoch: 23, loss: 0.068906\n",
      "epoch: 23, loss: 0.115533\n",
      "epoch: 23, loss: 0.061131\n",
      "epoch: 23, loss: 0.069441\n",
      "epoch: 23, loss: 0.039737\n",
      "epoch: 23, loss: 0.117848\n",
      "epoch: 23, loss: 0.087058\n",
      "epoch: 23, loss: 0.038495\n",
      "epoch: 24, loss: 0.098116\n",
      "epoch: 24, loss: 0.055985\n",
      "epoch: 24, loss: 0.121640\n",
      "epoch: 24, loss: 0.079035\n",
      "epoch: 24, loss: 0.047754\n",
      "epoch: 24, loss: 0.057413\n",
      "epoch: 24, loss: 0.093745\n",
      "epoch: 24, loss: 0.129157\n",
      "epoch: 24, loss: 0.087368\n",
      "epoch: 24, loss: 0.056526\n",
      "epoch: 24, loss: 0.079115\n",
      "epoch: 24, loss: 0.075558\n",
      "epoch: 24, loss: 0.072917\n",
      "epoch: 24, loss: 0.081523\n",
      "epoch: 24, loss: 0.082695\n",
      "epoch: 24, loss: 0.093654\n",
      "epoch: 24, loss: 0.069201\n",
      "epoch: 24, loss: 0.040390\n",
      "epoch: 24, loss: 0.097817\n",
      "epoch: 24, loss: 0.082792\n",
      "epoch: 24, loss: 0.062389\n",
      "epoch: 24, loss: 0.041981\n",
      "epoch: 24, loss: 0.128569\n",
      "epoch: 24, loss: 0.126715\n",
      "epoch: 24, loss: 0.113787\n",
      "epoch: 24, loss: 0.052961\n",
      "epoch: 24, loss: 0.023523\n",
      "epoch: 24, loss: 0.046864\n",
      "epoch: 24, loss: 0.087971\n",
      "epoch: 24, loss: 0.066045\n",
      "epoch: 24, loss: 0.130258\n",
      "epoch: 24, loss: 0.080140\n",
      "epoch: 24, loss: 0.094306\n",
      "epoch: 24, loss: 0.093693\n",
      "epoch: 24, loss: 0.045234\n",
      "epoch: 24, loss: 0.063186\n",
      "epoch: 24, loss: 0.066553\n",
      "epoch: 24, loss: 0.076365\n",
      "epoch: 24, loss: 0.049710\n",
      "epoch: 24, loss: 0.060880\n",
      "epoch: 24, loss: 0.017248\n",
      "epoch: 24, loss: 0.089817\n",
      "epoch: 24, loss: 0.106055\n",
      "epoch: 24, loss: 0.086459\n",
      "epoch: 24, loss: 0.069180\n",
      "epoch: 24, loss: 0.073121\n",
      "epoch: 24, loss: 0.080386\n",
      "epoch: 24, loss: 0.070859\n",
      "epoch: 24, loss: 0.123882\n",
      "epoch: 24, loss: 0.081025\n",
      "epoch: 24, loss: 0.073954\n",
      "epoch: 24, loss: 0.098670\n",
      "epoch: 24, loss: 0.072803\n",
      "epoch: 24, loss: 0.062354\n",
      "epoch: 24, loss: 0.082240\n",
      "epoch: 24, loss: 0.051275\n",
      "epoch: 24, loss: 0.138991\n",
      "epoch: 24, loss: 0.074041\n",
      "epoch: 24, loss: 0.067074\n",
      "epoch: 24, loss: 0.109122\n",
      "epoch: 24, loss: 0.049082\n",
      "epoch: 24, loss: 0.080812\n",
      "epoch: 24, loss: 0.087347\n",
      "epoch: 24, loss: 0.067807\n",
      "epoch: 24, loss: 0.061610\n",
      "epoch: 25, loss: 0.091024\n",
      "epoch: 25, loss: 0.071361\n",
      "epoch: 25, loss: 0.114562\n",
      "epoch: 25, loss: 0.094224\n",
      "epoch: 25, loss: 0.069152\n",
      "epoch: 25, loss: 0.059682\n",
      "epoch: 25, loss: 0.087465\n",
      "epoch: 25, loss: 0.094097\n",
      "epoch: 25, loss: 0.070554\n",
      "epoch: 25, loss: 0.077339\n",
      "epoch: 25, loss: 0.117195\n",
      "epoch: 25, loss: 0.095292\n",
      "epoch: 25, loss: 0.059494\n",
      "epoch: 25, loss: 0.086574\n",
      "epoch: 25, loss: 0.045782\n",
      "epoch: 25, loss: 0.027390\n",
      "epoch: 25, loss: 0.041829\n",
      "epoch: 25, loss: 0.076586\n",
      "epoch: 25, loss: 0.075014\n",
      "epoch: 25, loss: 0.115540\n",
      "epoch: 25, loss: 0.055866\n",
      "epoch: 25, loss: 0.071740\n",
      "epoch: 25, loss: 0.054378\n",
      "epoch: 25, loss: 0.057083\n",
      "epoch: 25, loss: 0.088622\n",
      "epoch: 25, loss: 0.053526\n",
      "epoch: 25, loss: 0.114909\n",
      "epoch: 25, loss: 0.043975\n",
      "epoch: 25, loss: 0.112284\n",
      "epoch: 25, loss: 0.058539\n",
      "epoch: 25, loss: 0.064898\n",
      "epoch: 25, loss: 0.078793\n",
      "epoch: 25, loss: 0.067366\n",
      "epoch: 25, loss: 0.111267\n",
      "epoch: 25, loss: 0.055556\n",
      "epoch: 25, loss: 0.038128\n",
      "epoch: 25, loss: 0.100828\n",
      "epoch: 25, loss: 0.130159\n",
      "epoch: 25, loss: 0.073528\n",
      "epoch: 25, loss: 0.104871\n",
      "epoch: 25, loss: 0.071728\n",
      "epoch: 25, loss: 0.076244\n",
      "epoch: 25, loss: 0.043756\n",
      "epoch: 25, loss: 0.102488\n",
      "epoch: 25, loss: 0.048833\n",
      "epoch: 25, loss: 0.088627\n",
      "epoch: 25, loss: 0.075879\n",
      "epoch: 25, loss: 0.201922\n",
      "epoch: 25, loss: 0.081979\n",
      "epoch: 25, loss: 0.060019\n",
      "epoch: 25, loss: 0.106386\n",
      "epoch: 25, loss: 0.094089\n",
      "epoch: 25, loss: 0.077507\n",
      "epoch: 25, loss: 0.066947\n",
      "epoch: 25, loss: 0.070635\n",
      "epoch: 25, loss: 0.113913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, loss: 0.072545\n",
      "epoch: 25, loss: 0.052597\n",
      "epoch: 25, loss: 0.062288\n",
      "epoch: 25, loss: 0.055891\n",
      "epoch: 25, loss: 0.028645\n",
      "epoch: 25, loss: 0.070673\n",
      "epoch: 25, loss: 0.074168\n",
      "epoch: 25, loss: 0.087745\n",
      "epoch: 25, loss: 0.016909\n",
      "epoch: 26, loss: 0.064285\n",
      "epoch: 26, loss: 0.108491\n",
      "epoch: 26, loss: 0.106132\n",
      "epoch: 26, loss: 0.067145\n",
      "epoch: 26, loss: 0.088321\n",
      "epoch: 26, loss: 0.087722\n",
      "epoch: 26, loss: 0.074124\n",
      "epoch: 26, loss: 0.045436\n",
      "epoch: 26, loss: 0.102562\n",
      "epoch: 26, loss: 0.071199\n",
      "epoch: 26, loss: 0.052199\n",
      "epoch: 26, loss: 0.076387\n",
      "epoch: 26, loss: 0.053624\n",
      "epoch: 26, loss: 0.079294\n",
      "epoch: 26, loss: 0.054127\n",
      "epoch: 26, loss: 0.035086\n",
      "epoch: 26, loss: 0.072558\n",
      "epoch: 26, loss: 0.034065\n",
      "epoch: 26, loss: 0.081215\n",
      "epoch: 26, loss: 0.106196\n",
      "epoch: 26, loss: 0.109359\n",
      "epoch: 26, loss: 0.077487\n",
      "epoch: 26, loss: 0.093033\n",
      "epoch: 26, loss: 0.022577\n",
      "epoch: 26, loss: 0.072062\n",
      "epoch: 26, loss: 0.094537\n",
      "epoch: 26, loss: 0.093117\n",
      "epoch: 26, loss: 0.064306\n",
      "epoch: 26, loss: 0.063603\n",
      "epoch: 26, loss: 0.182468\n",
      "epoch: 26, loss: 0.090366\n",
      "epoch: 26, loss: 0.033787\n",
      "epoch: 26, loss: 0.059031\n",
      "epoch: 26, loss: 0.050978\n",
      "epoch: 26, loss: 0.054645\n",
      "epoch: 26, loss: 0.060121\n",
      "epoch: 26, loss: 0.134580\n",
      "epoch: 26, loss: 0.077814\n",
      "epoch: 26, loss: 0.063427\n",
      "epoch: 26, loss: 0.086893\n",
      "epoch: 26, loss: 0.116240\n",
      "epoch: 26, loss: 0.099228\n",
      "epoch: 26, loss: 0.052201\n",
      "epoch: 26, loss: 0.098371\n",
      "epoch: 26, loss: 0.090607\n",
      "epoch: 26, loss: 0.091229\n",
      "epoch: 26, loss: 0.067660\n",
      "epoch: 26, loss: 0.098528\n",
      "epoch: 26, loss: 0.046432\n",
      "epoch: 26, loss: 0.081995\n",
      "epoch: 26, loss: 0.076216\n",
      "epoch: 26, loss: 0.087256\n",
      "epoch: 26, loss: 0.110860\n",
      "epoch: 26, loss: 0.087379\n",
      "epoch: 26, loss: 0.066103\n",
      "epoch: 26, loss: 0.053486\n",
      "epoch: 26, loss: 0.075539\n",
      "epoch: 26, loss: 0.084691\n",
      "epoch: 26, loss: 0.061123\n",
      "epoch: 26, loss: 0.069773\n",
      "epoch: 26, loss: 0.077447\n",
      "epoch: 26, loss: 0.078776\n",
      "epoch: 26, loss: 0.068152\n",
      "epoch: 26, loss: 0.051010\n",
      "epoch: 26, loss: 0.013754\n",
      "epoch: 27, loss: 0.063953\n",
      "epoch: 27, loss: 0.103311\n",
      "epoch: 27, loss: 0.069754\n",
      "epoch: 27, loss: 0.022318\n",
      "epoch: 27, loss: 0.082946\n",
      "epoch: 27, loss: 0.106757\n",
      "epoch: 27, loss: 0.069018\n",
      "epoch: 27, loss: 0.107728\n",
      "epoch: 27, loss: 0.047151\n",
      "epoch: 27, loss: 0.068772\n",
      "epoch: 27, loss: 0.039469\n",
      "epoch: 27, loss: 0.062318\n",
      "epoch: 27, loss: 0.112207\n",
      "epoch: 27, loss: 0.088850\n",
      "epoch: 27, loss: 0.081275\n",
      "epoch: 27, loss: 0.092054\n",
      "epoch: 27, loss: 0.025250\n",
      "epoch: 27, loss: 0.047410\n",
      "epoch: 27, loss: 0.096849\n",
      "epoch: 27, loss: 0.041181\n",
      "epoch: 27, loss: 0.053381\n",
      "epoch: 27, loss: 0.058102\n",
      "epoch: 27, loss: 0.052409\n",
      "epoch: 27, loss: 0.058755\n",
      "epoch: 27, loss: 0.039516\n",
      "epoch: 27, loss: 0.084919\n",
      "epoch: 27, loss: 0.031718\n",
      "epoch: 27, loss: 0.052468\n",
      "epoch: 27, loss: 0.097550\n",
      "epoch: 27, loss: 0.086294\n",
      "epoch: 27, loss: 0.070555\n",
      "epoch: 27, loss: 0.071005\n",
      "epoch: 27, loss: 0.107100\n",
      "epoch: 27, loss: 0.059038\n",
      "epoch: 27, loss: 0.071049\n",
      "epoch: 27, loss: 0.065688\n",
      "epoch: 27, loss: 0.130825\n",
      "epoch: 27, loss: 0.037008\n",
      "epoch: 27, loss: 0.075882\n",
      "epoch: 27, loss: 0.052233\n",
      "epoch: 27, loss: 0.087379\n",
      "epoch: 27, loss: 0.107363\n",
      "epoch: 27, loss: 0.152018\n",
      "epoch: 27, loss: 0.072957\n",
      "epoch: 27, loss: 0.034341\n",
      "epoch: 27, loss: 0.047012\n",
      "epoch: 27, loss: 0.110600\n",
      "epoch: 27, loss: 0.112767\n",
      "epoch: 27, loss: 0.112877\n",
      "epoch: 27, loss: 0.032804\n",
      "epoch: 27, loss: 0.062245\n",
      "epoch: 27, loss: 0.132216\n",
      "epoch: 27, loss: 0.124368\n",
      "epoch: 27, loss: 0.059532\n",
      "epoch: 27, loss: 0.062902\n",
      "epoch: 27, loss: 0.090023\n",
      "epoch: 27, loss: 0.046819\n",
      "epoch: 27, loss: 0.118399\n",
      "epoch: 27, loss: 0.076534\n",
      "epoch: 27, loss: 0.097420\n",
      "epoch: 27, loss: 0.085528\n",
      "epoch: 27, loss: 0.068059\n",
      "epoch: 27, loss: 0.096741\n",
      "epoch: 27, loss: 0.104956\n",
      "epoch: 27, loss: 0.106456\n",
      "epoch: 28, loss: 0.049411\n",
      "epoch: 28, loss: 0.065889\n",
      "epoch: 28, loss: 0.096752\n",
      "epoch: 28, loss: 0.026999\n",
      "epoch: 28, loss: 0.059167\n",
      "epoch: 28, loss: 0.061483\n",
      "epoch: 28, loss: 0.077570\n",
      "epoch: 28, loss: 0.092877\n",
      "epoch: 28, loss: 0.116269\n",
      "epoch: 28, loss: 0.027121\n",
      "epoch: 28, loss: 0.036635\n",
      "epoch: 28, loss: 0.063065\n",
      "epoch: 28, loss: 0.070735\n",
      "epoch: 28, loss: 0.072634\n",
      "epoch: 28, loss: 0.120873\n",
      "epoch: 28, loss: 0.158113\n",
      "epoch: 28, loss: 0.094290\n",
      "epoch: 28, loss: 0.020747\n",
      "epoch: 28, loss: 0.078326\n",
      "epoch: 28, loss: 0.109734\n",
      "epoch: 28, loss: 0.067031\n",
      "epoch: 28, loss: 0.089260\n",
      "epoch: 28, loss: 0.063556\n",
      "epoch: 28, loss: 0.076330\n",
      "epoch: 28, loss: 0.070440\n",
      "epoch: 28, loss: 0.101105\n",
      "epoch: 28, loss: 0.110199\n",
      "epoch: 28, loss: 0.116101\n",
      "epoch: 28, loss: 0.072909\n",
      "epoch: 28, loss: 0.092407\n",
      "epoch: 28, loss: 0.051410\n",
      "epoch: 28, loss: 0.051811\n",
      "epoch: 28, loss: 0.059170\n",
      "epoch: 28, loss: 0.125336\n",
      "epoch: 28, loss: 0.035244\n",
      "epoch: 28, loss: 0.078240\n",
      "epoch: 28, loss: 0.055242\n",
      "epoch: 28, loss: 0.058360\n",
      "epoch: 28, loss: 0.023161\n",
      "epoch: 28, loss: 0.060867\n",
      "epoch: 28, loss: 0.085396\n",
      "epoch: 28, loss: 0.054257\n",
      "epoch: 28, loss: 0.080655\n",
      "epoch: 28, loss: 0.069644\n",
      "epoch: 28, loss: 0.053040\n",
      "epoch: 28, loss: 0.050447\n",
      "epoch: 28, loss: 0.098818\n",
      "epoch: 28, loss: 0.074979\n",
      "epoch: 28, loss: 0.104640\n",
      "epoch: 28, loss: 0.086489\n",
      "epoch: 28, loss: 0.081405\n",
      "epoch: 28, loss: 0.073358\n",
      "epoch: 28, loss: 0.042647\n",
      "epoch: 28, loss: 0.049636\n",
      "epoch: 28, loss: 0.066644\n",
      "epoch: 28, loss: 0.085664\n",
      "epoch: 28, loss: 0.116895\n",
      "epoch: 28, loss: 0.033488\n",
      "epoch: 28, loss: 0.099932\n",
      "epoch: 28, loss: 0.118311\n",
      "epoch: 28, loss: 0.063144\n",
      "epoch: 28, loss: 0.085479\n",
      "epoch: 28, loss: 0.038228\n",
      "epoch: 28, loss: 0.126652\n",
      "epoch: 28, loss: 0.129577\n",
      "epoch: 29, loss: 0.045394\n",
      "epoch: 29, loss: 0.072710\n",
      "epoch: 29, loss: 0.033035\n",
      "epoch: 29, loss: 0.057601\n",
      "epoch: 29, loss: 0.088851\n",
      "epoch: 29, loss: 0.083748\n",
      "epoch: 29, loss: 0.122049\n",
      "epoch: 29, loss: 0.090874\n",
      "epoch: 29, loss: 0.094079\n",
      "epoch: 29, loss: 0.032773\n",
      "epoch: 29, loss: 0.053636\n",
      "epoch: 29, loss: 0.080963\n",
      "epoch: 29, loss: 0.033685\n",
      "epoch: 29, loss: 0.094994\n",
      "epoch: 29, loss: 0.071767\n",
      "epoch: 29, loss: 0.087581\n",
      "epoch: 29, loss: 0.028010\n",
      "epoch: 29, loss: 0.197103\n",
      "epoch: 29, loss: 0.096924\n",
      "epoch: 29, loss: 0.035218\n",
      "epoch: 29, loss: 0.134714\n",
      "epoch: 29, loss: 0.106541\n",
      "epoch: 29, loss: 0.067392\n",
      "epoch: 29, loss: 0.040759\n",
      "epoch: 29, loss: 0.096312\n",
      "epoch: 29, loss: 0.045214\n",
      "epoch: 29, loss: 0.082612\n",
      "epoch: 29, loss: 0.025554\n",
      "epoch: 29, loss: 0.092899\n",
      "epoch: 29, loss: 0.081507\n",
      "epoch: 29, loss: 0.143904\n",
      "epoch: 29, loss: 0.060370\n",
      "epoch: 29, loss: 0.069131\n",
      "epoch: 29, loss: 0.061291\n",
      "epoch: 29, loss: 0.098803\n",
      "epoch: 29, loss: 0.108536\n",
      "epoch: 29, loss: 0.064616\n",
      "epoch: 29, loss: 0.106487\n",
      "epoch: 29, loss: 0.009445\n",
      "epoch: 29, loss: 0.119063\n",
      "epoch: 29, loss: 0.054407\n",
      "epoch: 29, loss: 0.107938\n",
      "epoch: 29, loss: 0.039098\n",
      "epoch: 29, loss: 0.060182\n",
      "epoch: 29, loss: 0.051596\n",
      "epoch: 29, loss: 0.095284\n",
      "epoch: 29, loss: 0.061676\n",
      "epoch: 29, loss: 0.097594\n",
      "epoch: 29, loss: 0.067300\n",
      "epoch: 29, loss: 0.114664\n",
      "epoch: 29, loss: 0.089563\n",
      "epoch: 29, loss: 0.087197\n",
      "epoch: 29, loss: 0.103130\n",
      "epoch: 29, loss: 0.074826\n",
      "epoch: 29, loss: 0.083386\n",
      "epoch: 29, loss: 0.023124\n",
      "epoch: 29, loss: 0.054693\n",
      "epoch: 29, loss: 0.069691\n",
      "epoch: 29, loss: 0.066299\n",
      "epoch: 29, loss: 0.064538\n",
      "epoch: 29, loss: 0.030242\n",
      "epoch: 29, loss: 0.070928\n",
      "epoch: 29, loss: 0.081421\n",
      "epoch: 29, loss: 0.063072\n",
      "epoch: 29, loss: 0.067287\n",
      "epoch: 30, loss: 0.114441\n",
      "epoch: 30, loss: 0.109027\n",
      "epoch: 30, loss: 0.088551\n",
      "epoch: 30, loss: 0.083272\n",
      "epoch: 30, loss: 0.056545\n",
      "epoch: 30, loss: 0.073839\n",
      "epoch: 30, loss: 0.051655\n",
      "epoch: 30, loss: 0.097448\n",
      "epoch: 30, loss: 0.061834\n",
      "epoch: 30, loss: 0.041461\n",
      "epoch: 30, loss: 0.040162\n",
      "epoch: 30, loss: 0.141120\n",
      "epoch: 30, loss: 0.071546\n",
      "epoch: 30, loss: 0.143483\n",
      "epoch: 30, loss: 0.085661\n",
      "epoch: 30, loss: 0.050336\n",
      "epoch: 30, loss: 0.045079\n",
      "epoch: 30, loss: 0.079961\n",
      "epoch: 30, loss: 0.098135\n",
      "epoch: 30, loss: 0.068631\n",
      "epoch: 30, loss: 0.103086\n",
      "epoch: 30, loss: 0.052902\n",
      "epoch: 30, loss: 0.091141\n",
      "epoch: 30, loss: 0.116602\n",
      "epoch: 30, loss: 0.026184\n",
      "epoch: 30, loss: 0.087879\n",
      "epoch: 30, loss: 0.074510\n",
      "epoch: 30, loss: 0.038129\n",
      "epoch: 30, loss: 0.111119\n",
      "epoch: 30, loss: 0.092632\n",
      "epoch: 30, loss: 0.101828\n",
      "epoch: 30, loss: 0.032127\n",
      "epoch: 30, loss: 0.074539\n",
      "epoch: 30, loss: 0.099377\n",
      "epoch: 30, loss: 0.076745\n",
      "epoch: 30, loss: 0.046387\n",
      "epoch: 30, loss: 0.078503\n",
      "epoch: 30, loss: 0.104999\n",
      "epoch: 30, loss: 0.101645\n",
      "epoch: 30, loss: 0.053745\n",
      "epoch: 30, loss: 0.061467\n",
      "epoch: 30, loss: 0.094545\n",
      "epoch: 30, loss: 0.051009\n",
      "epoch: 30, loss: 0.110153\n",
      "epoch: 30, loss: 0.076765\n",
      "epoch: 30, loss: 0.033356\n",
      "epoch: 30, loss: 0.035660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, loss: 0.056580\n",
      "epoch: 30, loss: 0.100796\n",
      "epoch: 30, loss: 0.055586\n",
      "epoch: 30, loss: 0.075560\n",
      "epoch: 30, loss: 0.066614\n",
      "epoch: 30, loss: 0.060398\n",
      "epoch: 30, loss: 0.139106\n",
      "epoch: 30, loss: 0.078904\n",
      "epoch: 30, loss: 0.027733\n",
      "epoch: 30, loss: 0.076509\n",
      "epoch: 30, loss: 0.076008\n",
      "epoch: 30, loss: 0.091365\n",
      "epoch: 30, loss: 0.043789\n",
      "epoch: 30, loss: 0.105644\n",
      "epoch: 30, loss: 0.050880\n",
      "epoch: 30, loss: 0.047901\n",
      "epoch: 30, loss: 0.074114\n",
      "epoch: 30, loss: 0.019238\n",
      "epoch: 31, loss: 0.063747\n",
      "epoch: 31, loss: 0.024860\n",
      "epoch: 31, loss: 0.134344\n",
      "epoch: 31, loss: 0.064340\n",
      "epoch: 31, loss: 0.126870\n",
      "epoch: 31, loss: 0.095051\n",
      "epoch: 31, loss: 0.064556\n",
      "epoch: 31, loss: 0.083532\n",
      "epoch: 31, loss: 0.088579\n",
      "epoch: 31, loss: 0.083739\n",
      "epoch: 31, loss: 0.016860\n",
      "epoch: 31, loss: 0.070999\n",
      "epoch: 31, loss: 0.084655\n",
      "epoch: 31, loss: 0.109125\n",
      "epoch: 31, loss: 0.039701\n",
      "epoch: 31, loss: 0.121480\n",
      "epoch: 31, loss: 0.009756\n",
      "epoch: 31, loss: 0.072992\n",
      "epoch: 31, loss: 0.060581\n",
      "epoch: 31, loss: 0.096336\n",
      "epoch: 31, loss: 0.087013\n",
      "epoch: 31, loss: 0.112744\n",
      "epoch: 31, loss: 0.091344\n",
      "epoch: 31, loss: 0.042153\n",
      "epoch: 31, loss: 0.060779\n",
      "epoch: 31, loss: 0.086786\n",
      "epoch: 31, loss: 0.067052\n",
      "epoch: 31, loss: 0.057370\n",
      "epoch: 31, loss: 0.108801\n",
      "epoch: 31, loss: 0.065089\n",
      "epoch: 31, loss: 0.083393\n",
      "epoch: 31, loss: 0.055809\n",
      "epoch: 31, loss: 0.067567\n",
      "epoch: 31, loss: 0.098417\n",
      "epoch: 31, loss: 0.091570\n",
      "epoch: 31, loss: 0.087881\n",
      "epoch: 31, loss: 0.063949\n",
      "epoch: 31, loss: 0.064547\n",
      "epoch: 31, loss: 0.073723\n",
      "epoch: 31, loss: 0.042216\n",
      "epoch: 31, loss: 0.063944\n",
      "epoch: 31, loss: 0.058818\n",
      "epoch: 31, loss: 0.138563\n",
      "epoch: 31, loss: 0.022682\n",
      "epoch: 31, loss: 0.075143\n",
      "epoch: 31, loss: 0.118410\n",
      "epoch: 31, loss: 0.050304\n",
      "epoch: 31, loss: 0.076620\n",
      "epoch: 31, loss: 0.054588\n",
      "epoch: 31, loss: 0.033993\n",
      "epoch: 31, loss: 0.111216\n",
      "epoch: 31, loss: 0.032178\n",
      "epoch: 31, loss: 0.034855\n",
      "epoch: 31, loss: 0.099762\n",
      "epoch: 31, loss: 0.046328\n",
      "epoch: 31, loss: 0.065426\n",
      "epoch: 31, loss: 0.094366\n",
      "epoch: 31, loss: 0.085366\n",
      "epoch: 31, loss: 0.097443\n",
      "epoch: 31, loss: 0.084446\n",
      "epoch: 31, loss: 0.127089\n",
      "epoch: 31, loss: 0.110041\n",
      "epoch: 31, loss: 0.098510\n",
      "epoch: 31, loss: 0.048991\n",
      "epoch: 31, loss: 0.012594\n",
      "epoch: 32, loss: 0.048625\n",
      "epoch: 32, loss: 0.058423\n",
      "epoch: 32, loss: 0.082550\n",
      "epoch: 32, loss: 0.049597\n",
      "epoch: 32, loss: 0.122926\n",
      "epoch: 32, loss: 0.090428\n",
      "epoch: 32, loss: 0.092064\n",
      "epoch: 32, loss: 0.033275\n",
      "epoch: 32, loss: 0.061568\n",
      "epoch: 32, loss: 0.017291\n",
      "epoch: 32, loss: 0.087902\n",
      "epoch: 32, loss: 0.054456\n",
      "epoch: 32, loss: 0.081235\n",
      "epoch: 32, loss: 0.118916\n",
      "epoch: 32, loss: 0.087459\n",
      "epoch: 32, loss: 0.063506\n",
      "epoch: 32, loss: 0.116628\n",
      "epoch: 32, loss: 0.069116\n",
      "epoch: 32, loss: 0.099576\n",
      "epoch: 32, loss: 0.085384\n",
      "epoch: 32, loss: 0.064980\n",
      "epoch: 32, loss: 0.065763\n",
      "epoch: 32, loss: 0.055947\n",
      "epoch: 32, loss: 0.056464\n",
      "epoch: 32, loss: 0.067638\n",
      "epoch: 32, loss: 0.059943\n",
      "epoch: 32, loss: 0.019019\n",
      "epoch: 32, loss: 0.075593\n",
      "epoch: 32, loss: 0.051924\n",
      "epoch: 32, loss: 0.103264\n",
      "epoch: 32, loss: 0.154687\n",
      "epoch: 32, loss: 0.051474\n",
      "epoch: 32, loss: 0.089065\n",
      "epoch: 32, loss: 0.067970\n",
      "epoch: 32, loss: 0.084816\n",
      "epoch: 32, loss: 0.087802\n",
      "epoch: 32, loss: 0.114407\n",
      "epoch: 32, loss: 0.031561\n",
      "epoch: 32, loss: 0.041238\n",
      "epoch: 32, loss: 0.052081\n",
      "epoch: 32, loss: 0.070487\n",
      "epoch: 32, loss: 0.049068\n",
      "epoch: 32, loss: 0.122397\n",
      "epoch: 32, loss: 0.149880\n",
      "epoch: 32, loss: 0.145160\n",
      "epoch: 32, loss: 0.059183\n",
      "epoch: 32, loss: 0.064977\n",
      "epoch: 32, loss: 0.087855\n",
      "epoch: 32, loss: 0.027419\n",
      "epoch: 32, loss: 0.025318\n",
      "epoch: 32, loss: 0.037441\n",
      "epoch: 32, loss: 0.071642\n",
      "epoch: 32, loss: 0.054062\n",
      "epoch: 32, loss: 0.053449\n",
      "epoch: 32, loss: 0.060488\n",
      "epoch: 32, loss: 0.063629\n",
      "epoch: 32, loss: 0.130763\n",
      "epoch: 32, loss: 0.108969\n",
      "epoch: 32, loss: 0.079643\n",
      "epoch: 32, loss: 0.063429\n",
      "epoch: 32, loss: 0.085686\n",
      "epoch: 32, loss: 0.110726\n",
      "epoch: 32, loss: 0.062687\n",
      "epoch: 32, loss: 0.088518\n",
      "epoch: 32, loss: 0.068772\n",
      "epoch: 33, loss: 0.071777\n",
      "epoch: 33, loss: 0.075152\n",
      "epoch: 33, loss: 0.020817\n",
      "epoch: 33, loss: 0.069514\n",
      "epoch: 33, loss: 0.102814\n",
      "epoch: 33, loss: 0.106474\n",
      "epoch: 33, loss: 0.107167\n",
      "epoch: 33, loss: 0.012755\n",
      "epoch: 33, loss: 0.112394\n",
      "epoch: 33, loss: 0.080261\n",
      "epoch: 33, loss: 0.058673\n",
      "epoch: 33, loss: 0.070876\n",
      "epoch: 33, loss: 0.014543\n",
      "epoch: 33, loss: 0.081177\n",
      "epoch: 33, loss: 0.153077\n",
      "epoch: 33, loss: 0.056237\n",
      "epoch: 33, loss: 0.019233\n",
      "epoch: 33, loss: 0.044400\n",
      "epoch: 33, loss: 0.101544\n",
      "epoch: 33, loss: 0.075436\n",
      "epoch: 33, loss: 0.036750\n",
      "epoch: 33, loss: 0.043615\n",
      "epoch: 33, loss: 0.053110\n",
      "epoch: 33, loss: 0.054904\n",
      "epoch: 33, loss: 0.075749\n",
      "epoch: 33, loss: 0.063431\n",
      "epoch: 33, loss: 0.086451\n",
      "epoch: 33, loss: 0.065212\n",
      "epoch: 33, loss: 0.128311\n",
      "epoch: 33, loss: 0.097405\n",
      "epoch: 33, loss: 0.029087\n",
      "epoch: 33, loss: 0.057624\n",
      "epoch: 33, loss: 0.097970\n",
      "epoch: 33, loss: 0.090995\n",
      "epoch: 33, loss: 0.094265\n",
      "epoch: 33, loss: 0.089575\n",
      "epoch: 33, loss: 0.098773\n",
      "epoch: 33, loss: 0.041054\n",
      "epoch: 33, loss: 0.114655\n",
      "epoch: 33, loss: 0.093783\n",
      "epoch: 33, loss: 0.050415\n",
      "epoch: 33, loss: 0.103080\n",
      "epoch: 33, loss: 0.057851\n",
      "epoch: 33, loss: 0.049887\n",
      "epoch: 33, loss: 0.071185\n",
      "epoch: 33, loss: 0.095996\n",
      "epoch: 33, loss: 0.081453\n",
      "epoch: 33, loss: 0.033075\n",
      "epoch: 33, loss: 0.050367\n",
      "epoch: 33, loss: 0.081696\n",
      "epoch: 33, loss: 0.144229\n",
      "epoch: 33, loss: 0.084876\n",
      "epoch: 33, loss: 0.092301\n",
      "epoch: 33, loss: 0.064163\n",
      "epoch: 33, loss: 0.039748\n",
      "epoch: 33, loss: 0.096249\n",
      "epoch: 33, loss: 0.024643\n",
      "epoch: 33, loss: 0.062449\n",
      "epoch: 33, loss: 0.121981\n",
      "epoch: 33, loss: 0.023690\n",
      "epoch: 33, loss: 0.097246\n",
      "epoch: 33, loss: 0.019033\n",
      "epoch: 33, loss: 0.130549\n",
      "epoch: 33, loss: 0.063092\n",
      "epoch: 33, loss: 0.214688\n",
      "epoch: 34, loss: 0.072349\n",
      "epoch: 34, loss: 0.061106\n",
      "epoch: 34, loss: 0.073013\n",
      "epoch: 34, loss: 0.133601\n",
      "epoch: 34, loss: 0.043141\n",
      "epoch: 34, loss: 0.072631\n",
      "epoch: 34, loss: 0.046554\n",
      "epoch: 34, loss: 0.073226\n",
      "epoch: 34, loss: 0.055549\n",
      "epoch: 34, loss: 0.050416\n",
      "epoch: 34, loss: 0.061042\n",
      "epoch: 34, loss: 0.043451\n",
      "epoch: 34, loss: 0.079954\n",
      "epoch: 34, loss: 0.101030\n",
      "epoch: 34, loss: 0.066974\n",
      "epoch: 34, loss: 0.088967\n",
      "epoch: 34, loss: 0.089053\n",
      "epoch: 34, loss: 0.088097\n",
      "epoch: 34, loss: 0.135594\n",
      "epoch: 34, loss: 0.006568\n",
      "epoch: 34, loss: 0.113774\n",
      "epoch: 34, loss: 0.105129\n",
      "epoch: 34, loss: 0.068948\n",
      "epoch: 34, loss: 0.066175\n",
      "epoch: 34, loss: 0.040866\n",
      "epoch: 34, loss: 0.066309\n",
      "epoch: 34, loss: 0.070323\n",
      "epoch: 34, loss: 0.097303\n",
      "epoch: 34, loss: 0.054645\n",
      "epoch: 34, loss: 0.080645\n",
      "epoch: 34, loss: 0.090527\n",
      "epoch: 34, loss: 0.081678\n",
      "epoch: 34, loss: 0.089243\n",
      "epoch: 34, loss: 0.059646\n",
      "epoch: 34, loss: 0.063353\n",
      "epoch: 34, loss: 0.095101\n",
      "epoch: 34, loss: 0.082764\n",
      "epoch: 34, loss: 0.031254\n",
      "epoch: 34, loss: 0.117709\n",
      "epoch: 34, loss: 0.047770\n",
      "epoch: 34, loss: 0.076559\n",
      "epoch: 34, loss: 0.036968\n",
      "epoch: 34, loss: 0.090123\n",
      "epoch: 34, loss: 0.058908\n",
      "epoch: 34, loss: 0.153983\n",
      "epoch: 34, loss: 0.123386\n",
      "epoch: 34, loss: 0.082542\n",
      "epoch: 34, loss: 0.081995\n",
      "epoch: 34, loss: 0.105164\n",
      "epoch: 34, loss: 0.012456\n",
      "epoch: 34, loss: 0.057151\n",
      "epoch: 34, loss: 0.074626\n",
      "epoch: 34, loss: 0.051268\n",
      "epoch: 34, loss: 0.149638\n",
      "epoch: 34, loss: 0.076643\n",
      "epoch: 34, loss: 0.062468\n",
      "epoch: 34, loss: 0.048631\n",
      "epoch: 34, loss: 0.113541\n",
      "epoch: 34, loss: 0.060432\n",
      "epoch: 34, loss: 0.034370\n",
      "epoch: 34, loss: 0.040551\n",
      "epoch: 34, loss: 0.152865\n",
      "epoch: 34, loss: 0.042873\n",
      "epoch: 34, loss: 0.051205\n",
      "epoch: 34, loss: 0.090784\n",
      "epoch: 35, loss: 0.058650\n",
      "epoch: 35, loss: 0.083807\n",
      "epoch: 35, loss: 0.068789\n",
      "epoch: 35, loss: 0.073165\n",
      "epoch: 35, loss: 0.107621\n",
      "epoch: 35, loss: 0.078636\n",
      "epoch: 35, loss: 0.125693\n",
      "epoch: 35, loss: 0.067564\n",
      "epoch: 35, loss: 0.073541\n",
      "epoch: 35, loss: 0.043974\n",
      "epoch: 35, loss: 0.059434\n",
      "epoch: 35, loss: 0.057355\n",
      "epoch: 35, loss: 0.020569\n",
      "epoch: 35, loss: 0.071232\n",
      "epoch: 35, loss: 0.105106\n",
      "epoch: 35, loss: 0.061727\n",
      "epoch: 35, loss: 0.072431\n",
      "epoch: 35, loss: 0.062613\n",
      "epoch: 35, loss: 0.124971\n",
      "epoch: 35, loss: 0.130568\n",
      "epoch: 35, loss: 0.022507\n",
      "epoch: 35, loss: 0.077067\n",
      "epoch: 35, loss: 0.103184\n",
      "epoch: 35, loss: 0.095245\n",
      "epoch: 35, loss: 0.090187\n",
      "epoch: 35, loss: 0.108692\n",
      "epoch: 35, loss: 0.046854\n",
      "epoch: 35, loss: 0.067404\n",
      "epoch: 35, loss: 0.063640\n",
      "epoch: 35, loss: 0.040507\n",
      "epoch: 35, loss: 0.080666\n",
      "epoch: 35, loss: 0.099695\n",
      "epoch: 35, loss: 0.032073\n",
      "epoch: 35, loss: 0.053769\n",
      "epoch: 35, loss: 0.071596\n",
      "epoch: 35, loss: 0.083933\n",
      "epoch: 35, loss: 0.095624\n",
      "epoch: 35, loss: 0.087099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, loss: 0.084273\n",
      "epoch: 35, loss: 0.132425\n",
      "epoch: 35, loss: 0.026999\n",
      "epoch: 35, loss: 0.119850\n",
      "epoch: 35, loss: 0.038552\n",
      "epoch: 35, loss: 0.066105\n",
      "epoch: 35, loss: 0.091662\n",
      "epoch: 35, loss: 0.071728\n",
      "epoch: 35, loss: 0.057822\n",
      "epoch: 35, loss: 0.150542\n",
      "epoch: 35, loss: 0.087617\n",
      "epoch: 35, loss: 0.071902\n",
      "epoch: 35, loss: 0.085147\n",
      "epoch: 35, loss: 0.085141\n",
      "epoch: 35, loss: 0.040405\n",
      "epoch: 35, loss: 0.016943\n",
      "epoch: 35, loss: 0.015747\n",
      "epoch: 35, loss: 0.108606\n",
      "epoch: 35, loss: 0.064946\n",
      "epoch: 35, loss: 0.040054\n",
      "epoch: 35, loss: 0.050699\n",
      "epoch: 35, loss: 0.035574\n",
      "epoch: 35, loss: 0.062853\n",
      "epoch: 35, loss: 0.083654\n",
      "epoch: 35, loss: 0.090805\n",
      "epoch: 35, loss: 0.076024\n",
      "epoch: 35, loss: 0.121633\n",
      "epoch: 36, loss: 0.065801\n",
      "epoch: 36, loss: 0.107972\n",
      "epoch: 36, loss: 0.135398\n",
      "epoch: 36, loss: 0.080723\n",
      "epoch: 36, loss: 0.085133\n",
      "epoch: 36, loss: 0.083872\n",
      "epoch: 36, loss: 0.082915\n",
      "epoch: 36, loss: 0.084193\n",
      "epoch: 36, loss: 0.088901\n",
      "epoch: 36, loss: 0.089355\n",
      "epoch: 36, loss: 0.055919\n",
      "epoch: 36, loss: 0.076880\n",
      "epoch: 36, loss: 0.109935\n",
      "epoch: 36, loss: 0.032099\n",
      "epoch: 36, loss: 0.138818\n",
      "epoch: 36, loss: 0.104803\n",
      "epoch: 36, loss: 0.122496\n",
      "epoch: 36, loss: 0.076641\n",
      "epoch: 36, loss: 0.090544\n",
      "epoch: 36, loss: 0.064632\n",
      "epoch: 36, loss: 0.025183\n",
      "epoch: 36, loss: 0.062762\n",
      "epoch: 36, loss: 0.052162\n",
      "epoch: 36, loss: 0.044852\n",
      "epoch: 36, loss: 0.083451\n",
      "epoch: 36, loss: 0.077554\n",
      "epoch: 36, loss: 0.053390\n",
      "epoch: 36, loss: 0.023458\n",
      "epoch: 36, loss: 0.088078\n",
      "epoch: 36, loss: 0.100993\n",
      "epoch: 36, loss: 0.060725\n",
      "epoch: 36, loss: 0.075750\n",
      "epoch: 36, loss: 0.042537\n",
      "epoch: 36, loss: 0.068872\n",
      "epoch: 36, loss: 0.034765\n",
      "epoch: 36, loss: 0.076178\n",
      "epoch: 36, loss: 0.054419\n",
      "epoch: 36, loss: 0.097638\n",
      "epoch: 36, loss: 0.078557\n",
      "epoch: 36, loss: 0.061897\n",
      "epoch: 36, loss: 0.054493\n",
      "epoch: 36, loss: 0.093102\n",
      "epoch: 36, loss: 0.090524\n",
      "epoch: 36, loss: 0.061217\n",
      "epoch: 36, loss: 0.105632\n",
      "epoch: 36, loss: 0.088621\n",
      "epoch: 36, loss: 0.079738\n",
      "epoch: 36, loss: 0.096527\n",
      "epoch: 36, loss: 0.056456\n",
      "epoch: 36, loss: 0.065596\n",
      "epoch: 36, loss: 0.079973\n",
      "epoch: 36, loss: 0.018774\n",
      "epoch: 36, loss: 0.050292\n",
      "epoch: 36, loss: 0.054327\n",
      "epoch: 36, loss: 0.041096\n",
      "epoch: 36, loss: 0.063417\n",
      "epoch: 36, loss: 0.078755\n",
      "epoch: 36, loss: 0.053502\n",
      "epoch: 36, loss: 0.076176\n",
      "epoch: 36, loss: 0.080705\n",
      "epoch: 36, loss: 0.086634\n",
      "epoch: 36, loss: 0.081706\n",
      "epoch: 36, loss: 0.075205\n",
      "epoch: 36, loss: 0.010124\n",
      "epoch: 36, loss: 0.042122\n",
      "epoch: 37, loss: 0.056834\n",
      "epoch: 37, loss: 0.098062\n",
      "epoch: 37, loss: 0.079377\n",
      "epoch: 37, loss: 0.054124\n",
      "epoch: 37, loss: 0.048874\n",
      "epoch: 37, loss: 0.068918\n",
      "epoch: 37, loss: 0.070976\n",
      "epoch: 37, loss: 0.046601\n",
      "epoch: 37, loss: 0.079847\n",
      "epoch: 37, loss: 0.071856\n",
      "epoch: 37, loss: 0.095111\n",
      "epoch: 37, loss: 0.047232\n",
      "epoch: 37, loss: 0.039772\n",
      "epoch: 37, loss: 0.075852\n",
      "epoch: 37, loss: 0.068961\n",
      "epoch: 37, loss: 0.102153\n",
      "epoch: 37, loss: 0.092165\n",
      "epoch: 37, loss: 0.063473\n",
      "epoch: 37, loss: 0.061350\n",
      "epoch: 37, loss: 0.079331\n",
      "epoch: 37, loss: 0.078073\n",
      "epoch: 37, loss: 0.055244\n",
      "epoch: 37, loss: 0.076025\n",
      "epoch: 37, loss: 0.109453\n",
      "epoch: 37, loss: 0.054671\n",
      "epoch: 37, loss: 0.083580\n",
      "epoch: 37, loss: 0.026234\n",
      "epoch: 37, loss: 0.096444\n",
      "epoch: 37, loss: 0.039499\n",
      "epoch: 37, loss: 0.045539\n",
      "epoch: 37, loss: 0.051900\n",
      "epoch: 37, loss: 0.083537\n",
      "epoch: 37, loss: 0.096622\n",
      "epoch: 37, loss: 0.073550\n",
      "epoch: 37, loss: 0.056255\n",
      "epoch: 37, loss: 0.031508\n",
      "epoch: 37, loss: 0.081027\n",
      "epoch: 37, loss: 0.070712\n",
      "epoch: 37, loss: 0.063962\n",
      "epoch: 37, loss: 0.042749\n",
      "epoch: 37, loss: 0.037149\n",
      "epoch: 37, loss: 0.085891\n",
      "epoch: 37, loss: 0.138431\n",
      "epoch: 37, loss: 0.118867\n",
      "epoch: 37, loss: 0.060378\n",
      "epoch: 37, loss: 0.098744\n",
      "epoch: 37, loss: 0.048690\n",
      "epoch: 37, loss: 0.081360\n",
      "epoch: 37, loss: 0.063638\n",
      "epoch: 37, loss: 0.116304\n",
      "epoch: 37, loss: 0.069499\n",
      "epoch: 37, loss: 0.128838\n",
      "epoch: 37, loss: 0.052843\n",
      "epoch: 37, loss: 0.084070\n",
      "epoch: 37, loss: 0.069320\n",
      "epoch: 37, loss: 0.067457\n",
      "epoch: 37, loss: 0.062086\n",
      "epoch: 37, loss: 0.140589\n",
      "epoch: 37, loss: 0.046698\n",
      "epoch: 37, loss: 0.060177\n",
      "epoch: 37, loss: 0.123767\n",
      "epoch: 37, loss: 0.045051\n",
      "epoch: 37, loss: 0.073832\n",
      "epoch: 37, loss: 0.097369\n",
      "epoch: 37, loss: 0.012160\n",
      "epoch: 38, loss: 0.084432\n",
      "epoch: 38, loss: 0.093800\n",
      "epoch: 38, loss: 0.099333\n",
      "epoch: 38, loss: 0.086577\n",
      "epoch: 38, loss: 0.008330\n",
      "epoch: 38, loss: 0.014843\n",
      "epoch: 38, loss: 0.052500\n",
      "epoch: 38, loss: 0.022119\n",
      "epoch: 38, loss: 0.081622\n",
      "epoch: 38, loss: 0.096813\n",
      "epoch: 38, loss: 0.096497\n",
      "epoch: 38, loss: 0.062588\n",
      "epoch: 38, loss: 0.045506\n",
      "epoch: 38, loss: 0.059520\n",
      "epoch: 38, loss: 0.102011\n",
      "epoch: 38, loss: 0.054156\n",
      "epoch: 38, loss: 0.059174\n",
      "epoch: 38, loss: 0.103358\n",
      "epoch: 38, loss: 0.060078\n",
      "epoch: 38, loss: 0.131004\n",
      "epoch: 38, loss: 0.103041\n",
      "epoch: 38, loss: 0.090268\n",
      "epoch: 38, loss: 0.050721\n",
      "epoch: 38, loss: 0.099082\n",
      "epoch: 38, loss: 0.083329\n",
      "epoch: 38, loss: 0.069440\n",
      "epoch: 38, loss: 0.056076\n",
      "epoch: 38, loss: 0.095002\n",
      "epoch: 38, loss: 0.093686\n",
      "epoch: 38, loss: 0.072703\n",
      "epoch: 38, loss: 0.083912\n",
      "epoch: 38, loss: 0.137729\n",
      "epoch: 38, loss: 0.045381\n",
      "epoch: 38, loss: 0.094432\n",
      "epoch: 38, loss: 0.120233\n",
      "epoch: 38, loss: 0.091951\n",
      "epoch: 38, loss: 0.059056\n",
      "epoch: 38, loss: 0.074138\n",
      "epoch: 38, loss: 0.030292\n",
      "epoch: 38, loss: 0.057326\n",
      "epoch: 38, loss: 0.074179\n",
      "epoch: 38, loss: 0.048713\n",
      "epoch: 38, loss: 0.073461\n",
      "epoch: 38, loss: 0.116019\n",
      "epoch: 38, loss: 0.086077\n",
      "epoch: 38, loss: 0.111080\n",
      "epoch: 38, loss: 0.095796\n",
      "epoch: 38, loss: 0.077511\n",
      "epoch: 38, loss: 0.082606\n",
      "epoch: 38, loss: 0.096068\n",
      "epoch: 38, loss: 0.038563\n",
      "epoch: 38, loss: 0.044387\n",
      "epoch: 38, loss: 0.090046\n",
      "epoch: 38, loss: 0.105120\n",
      "epoch: 38, loss: 0.049675\n",
      "epoch: 38, loss: 0.027105\n",
      "epoch: 38, loss: 0.010806\n",
      "epoch: 38, loss: 0.039354\n",
      "epoch: 38, loss: 0.080900\n",
      "epoch: 38, loss: 0.059185\n",
      "epoch: 38, loss: 0.106556\n",
      "epoch: 38, loss: 0.086869\n",
      "epoch: 38, loss: 0.019752\n",
      "epoch: 38, loss: 0.028165\n",
      "epoch: 38, loss: 0.077095\n",
      "epoch: 39, loss: 0.076718\n",
      "epoch: 39, loss: 0.093541\n",
      "epoch: 39, loss: 0.021982\n",
      "epoch: 39, loss: 0.100161\n",
      "epoch: 39, loss: 0.059782\n",
      "epoch: 39, loss: 0.088507\n",
      "epoch: 39, loss: 0.093592\n",
      "epoch: 39, loss: 0.021087\n",
      "epoch: 39, loss: 0.094507\n",
      "epoch: 39, loss: 0.085462\n",
      "epoch: 39, loss: 0.054769\n",
      "epoch: 39, loss: 0.053633\n",
      "epoch: 39, loss: 0.100042\n",
      "epoch: 39, loss: 0.054758\n",
      "epoch: 39, loss: 0.034300\n",
      "epoch: 39, loss: 0.095778\n",
      "epoch: 39, loss: 0.064206\n",
      "epoch: 39, loss: 0.087968\n",
      "epoch: 39, loss: 0.047533\n",
      "epoch: 39, loss: 0.075859\n",
      "epoch: 39, loss: 0.074998\n",
      "epoch: 39, loss: 0.071153\n",
      "epoch: 39, loss: 0.025074\n",
      "epoch: 39, loss: 0.067533\n",
      "epoch: 39, loss: 0.057441\n",
      "epoch: 39, loss: 0.112950\n",
      "epoch: 39, loss: 0.071296\n",
      "epoch: 39, loss: 0.021319\n",
      "epoch: 39, loss: 0.072213\n",
      "epoch: 39, loss: 0.057321\n",
      "epoch: 39, loss: 0.075457\n",
      "epoch: 39, loss: 0.069668\n",
      "epoch: 39, loss: 0.116057\n",
      "epoch: 39, loss: 0.047430\n",
      "epoch: 39, loss: 0.065877\n",
      "epoch: 39, loss: 0.044447\n",
      "epoch: 39, loss: 0.061835\n",
      "epoch: 39, loss: 0.055634\n",
      "epoch: 39, loss: 0.040743\n",
      "epoch: 39, loss: 0.037669\n",
      "epoch: 39, loss: 0.107116\n",
      "epoch: 39, loss: 0.103630\n",
      "epoch: 39, loss: 0.024699\n",
      "epoch: 39, loss: 0.060842\n",
      "epoch: 39, loss: 0.145303\n",
      "epoch: 39, loss: 0.064394\n",
      "epoch: 39, loss: 0.112402\n",
      "epoch: 39, loss: 0.135202\n",
      "epoch: 39, loss: 0.037850\n",
      "epoch: 39, loss: 0.108979\n",
      "epoch: 39, loss: 0.096916\n",
      "epoch: 39, loss: 0.052997\n",
      "epoch: 39, loss: 0.071649\n",
      "epoch: 39, loss: 0.019328\n",
      "epoch: 39, loss: 0.074899\n",
      "epoch: 39, loss: 0.084481\n",
      "epoch: 39, loss: 0.155944\n",
      "epoch: 39, loss: 0.059199\n",
      "epoch: 39, loss: 0.096101\n",
      "epoch: 39, loss: 0.055930\n",
      "epoch: 39, loss: 0.065165\n",
      "epoch: 39, loss: 0.095735\n",
      "epoch: 39, loss: 0.064710\n",
      "epoch: 39, loss: 0.071006\n",
      "epoch: 39, loss: 0.119021\n",
      "epoch: 40, loss: 0.109437\n",
      "epoch: 40, loss: 0.046899\n",
      "epoch: 40, loss: 0.113217\n",
      "epoch: 40, loss: 0.056083\n",
      "epoch: 40, loss: 0.093855\n",
      "epoch: 40, loss: 0.024900\n",
      "epoch: 40, loss: 0.106843\n",
      "epoch: 40, loss: 0.037589\n",
      "epoch: 40, loss: 0.037050\n",
      "epoch: 40, loss: 0.070632\n",
      "epoch: 40, loss: 0.089818\n",
      "epoch: 40, loss: 0.029844\n",
      "epoch: 40, loss: 0.071450\n",
      "epoch: 40, loss: 0.046740\n",
      "epoch: 40, loss: 0.094462\n",
      "epoch: 40, loss: 0.053090\n",
      "epoch: 40, loss: 0.114817\n",
      "epoch: 40, loss: 0.086380\n",
      "epoch: 40, loss: 0.066490\n",
      "epoch: 40, loss: 0.028712\n",
      "epoch: 40, loss: 0.044996\n",
      "epoch: 40, loss: 0.059064\n",
      "epoch: 40, loss: 0.058054\n",
      "epoch: 40, loss: 0.028718\n",
      "epoch: 40, loss: 0.082043\n",
      "epoch: 40, loss: 0.031193\n",
      "epoch: 40, loss: 0.051399\n",
      "epoch: 40, loss: 0.124927\n",
      "epoch: 40, loss: 0.057694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40, loss: 0.087812\n",
      "epoch: 40, loss: 0.069437\n",
      "epoch: 40, loss: 0.105447\n",
      "epoch: 40, loss: 0.078586\n",
      "epoch: 40, loss: 0.083368\n",
      "epoch: 40, loss: 0.124496\n",
      "epoch: 40, loss: 0.037990\n",
      "epoch: 40, loss: 0.051734\n",
      "epoch: 40, loss: 0.084545\n",
      "epoch: 40, loss: 0.033048\n",
      "epoch: 40, loss: 0.083514\n",
      "epoch: 40, loss: 0.047179\n",
      "epoch: 40, loss: 0.115073\n",
      "epoch: 40, loss: 0.025567\n",
      "epoch: 40, loss: 0.064212\n",
      "epoch: 40, loss: 0.091561\n",
      "epoch: 40, loss: 0.075573\n",
      "epoch: 40, loss: 0.059337\n",
      "epoch: 40, loss: 0.053790\n",
      "epoch: 40, loss: 0.078383\n",
      "epoch: 40, loss: 0.087241\n",
      "epoch: 40, loss: 0.132961\n",
      "epoch: 40, loss: 0.048461\n",
      "epoch: 40, loss: 0.086012\n",
      "epoch: 40, loss: 0.070728\n",
      "epoch: 40, loss: 0.107169\n",
      "epoch: 40, loss: 0.077443\n",
      "epoch: 40, loss: 0.082494\n",
      "epoch: 40, loss: 0.068086\n",
      "epoch: 40, loss: 0.070281\n",
      "epoch: 40, loss: 0.122772\n",
      "epoch: 40, loss: 0.070280\n",
      "epoch: 40, loss: 0.081707\n",
      "epoch: 40, loss: 0.087780\n",
      "epoch: 40, loss: 0.058500\n",
      "epoch: 40, loss: 0.010911\n",
      "epoch: 41, loss: 0.050363\n",
      "epoch: 41, loss: 0.076287\n",
      "epoch: 41, loss: 0.070405\n",
      "epoch: 41, loss: 0.143665\n",
      "epoch: 41, loss: 0.098322\n",
      "epoch: 41, loss: 0.099082\n",
      "epoch: 41, loss: 0.044763\n",
      "epoch: 41, loss: 0.077225\n",
      "epoch: 41, loss: 0.026661\n",
      "epoch: 41, loss: 0.044662\n",
      "epoch: 41, loss: 0.089704\n",
      "epoch: 41, loss: 0.019357\n",
      "epoch: 41, loss: 0.062223\n",
      "epoch: 41, loss: 0.096930\n",
      "epoch: 41, loss: 0.134666\n",
      "epoch: 41, loss: 0.017779\n",
      "epoch: 41, loss: 0.065876\n",
      "epoch: 41, loss: 0.088236\n",
      "epoch: 41, loss: 0.043442\n",
      "epoch: 41, loss: 0.058334\n",
      "epoch: 41, loss: 0.079145\n",
      "epoch: 41, loss: 0.085594\n",
      "epoch: 41, loss: 0.065184\n",
      "epoch: 41, loss: 0.100692\n",
      "epoch: 41, loss: 0.095669\n",
      "epoch: 41, loss: 0.007962\n",
      "epoch: 41, loss: 0.105261\n",
      "epoch: 41, loss: 0.073762\n",
      "epoch: 41, loss: 0.010952\n",
      "epoch: 41, loss: 0.065558\n",
      "epoch: 41, loss: 0.043043\n",
      "epoch: 41, loss: 0.106723\n",
      "epoch: 41, loss: 0.038994\n",
      "epoch: 41, loss: 0.079250\n",
      "epoch: 41, loss: 0.093158\n",
      "epoch: 41, loss: 0.086308\n",
      "epoch: 41, loss: 0.039237\n",
      "epoch: 41, loss: 0.079003\n",
      "epoch: 41, loss: 0.119933\n",
      "epoch: 41, loss: 0.041059\n",
      "epoch: 41, loss: 0.037017\n",
      "epoch: 41, loss: 0.044309\n",
      "epoch: 41, loss: 0.052267\n",
      "epoch: 41, loss: 0.064343\n",
      "epoch: 41, loss: 0.094642\n",
      "epoch: 41, loss: 0.074826\n",
      "epoch: 41, loss: 0.083029\n",
      "epoch: 41, loss: 0.051696\n",
      "epoch: 41, loss: 0.038819\n",
      "epoch: 41, loss: 0.094000\n",
      "epoch: 41, loss: 0.090027\n",
      "epoch: 41, loss: 0.063740\n",
      "epoch: 41, loss: 0.084916\n",
      "epoch: 41, loss: 0.048070\n",
      "epoch: 41, loss: 0.087267\n",
      "epoch: 41, loss: 0.057926\n",
      "epoch: 41, loss: 0.112874\n",
      "epoch: 41, loss: 0.088184\n",
      "epoch: 41, loss: 0.128684\n",
      "epoch: 41, loss: 0.060054\n",
      "epoch: 41, loss: 0.076490\n",
      "epoch: 41, loss: 0.043949\n",
      "epoch: 41, loss: 0.089488\n",
      "epoch: 41, loss: 0.093372\n",
      "epoch: 41, loss: 0.051325\n",
      "epoch: 42, loss: 0.056122\n",
      "epoch: 42, loss: 0.056359\n",
      "epoch: 42, loss: 0.101293\n",
      "epoch: 42, loss: 0.052117\n",
      "epoch: 42, loss: 0.031737\n",
      "epoch: 42, loss: 0.076288\n",
      "epoch: 42, loss: 0.102720\n",
      "epoch: 42, loss: 0.053469\n",
      "epoch: 42, loss: 0.108546\n",
      "epoch: 42, loss: 0.052209\n",
      "epoch: 42, loss: 0.057074\n",
      "epoch: 42, loss: 0.031887\n",
      "epoch: 42, loss: 0.042479\n",
      "epoch: 42, loss: 0.095046\n",
      "epoch: 42, loss: 0.048876\n",
      "epoch: 42, loss: 0.087532\n",
      "epoch: 42, loss: 0.027792\n",
      "epoch: 42, loss: 0.014052\n",
      "epoch: 42, loss: 0.074016\n",
      "epoch: 42, loss: 0.039320\n",
      "epoch: 42, loss: 0.075486\n",
      "epoch: 42, loss: 0.057659\n",
      "epoch: 42, loss: 0.038179\n",
      "epoch: 42, loss: 0.099722\n",
      "epoch: 42, loss: 0.080416\n",
      "epoch: 42, loss: 0.072574\n",
      "epoch: 42, loss: 0.075380\n",
      "epoch: 42, loss: 0.110490\n",
      "epoch: 42, loss: 0.094092\n",
      "epoch: 42, loss: 0.101898\n",
      "epoch: 42, loss: 0.061517\n",
      "epoch: 42, loss: 0.066615\n",
      "epoch: 42, loss: 0.048836\n",
      "epoch: 42, loss: 0.068350\n",
      "epoch: 42, loss: 0.020463\n",
      "epoch: 42, loss: 0.037634\n",
      "epoch: 42, loss: 0.098814\n",
      "epoch: 42, loss: 0.071377\n",
      "epoch: 42, loss: 0.053935\n",
      "epoch: 42, loss: 0.056659\n",
      "epoch: 42, loss: 0.040575\n",
      "epoch: 42, loss: 0.087289\n",
      "epoch: 42, loss: 0.083052\n",
      "epoch: 42, loss: 0.040429\n",
      "epoch: 42, loss: 0.095993\n",
      "epoch: 42, loss: 0.100283\n",
      "epoch: 42, loss: 0.084272\n",
      "epoch: 42, loss: 0.026070\n",
      "epoch: 42, loss: 0.100534\n",
      "epoch: 42, loss: 0.037438\n",
      "epoch: 42, loss: 0.062794\n",
      "epoch: 42, loss: 0.061142\n",
      "epoch: 42, loss: 0.102380\n",
      "epoch: 42, loss: 0.061250\n",
      "epoch: 42, loss: 0.070980\n",
      "epoch: 42, loss: 0.129134\n",
      "epoch: 42, loss: 0.110682\n",
      "epoch: 42, loss: 0.132477\n",
      "epoch: 42, loss: 0.121583\n",
      "epoch: 42, loss: 0.073731\n",
      "epoch: 42, loss: 0.039097\n",
      "epoch: 42, loss: 0.099411\n",
      "epoch: 42, loss: 0.103444\n",
      "epoch: 42, loss: 0.107201\n",
      "epoch: 42, loss: 0.009866\n",
      "epoch: 43, loss: 0.098289\n",
      "epoch: 43, loss: 0.117918\n",
      "epoch: 43, loss: 0.064519\n",
      "epoch: 43, loss: 0.064496\n",
      "epoch: 43, loss: 0.067512\n",
      "epoch: 43, loss: 0.102497\n",
      "epoch: 43, loss: 0.107264\n",
      "epoch: 43, loss: 0.065741\n",
      "epoch: 43, loss: 0.073052\n",
      "epoch: 43, loss: 0.062609\n",
      "epoch: 43, loss: 0.114280\n",
      "epoch: 43, loss: 0.047479\n",
      "epoch: 43, loss: 0.092150\n",
      "epoch: 43, loss: 0.055232\n",
      "epoch: 43, loss: 0.040679\n",
      "epoch: 43, loss: 0.109768\n",
      "epoch: 43, loss: 0.111582\n",
      "epoch: 43, loss: 0.055597\n",
      "epoch: 43, loss: 0.080428\n",
      "epoch: 43, loss: 0.149430\n",
      "epoch: 43, loss: 0.050470\n",
      "epoch: 43, loss: 0.106968\n",
      "epoch: 43, loss: 0.089251\n",
      "epoch: 43, loss: 0.040173\n",
      "epoch: 43, loss: 0.081458\n",
      "epoch: 43, loss: 0.053726\n",
      "epoch: 43, loss: 0.067640\n",
      "epoch: 43, loss: 0.066551\n",
      "epoch: 43, loss: 0.070507\n",
      "epoch: 43, loss: 0.069865\n",
      "epoch: 43, loss: 0.110090\n",
      "epoch: 43, loss: 0.088313\n",
      "epoch: 43, loss: 0.045393\n",
      "epoch: 43, loss: 0.082522\n",
      "epoch: 43, loss: 0.054017\n",
      "epoch: 43, loss: 0.036720\n",
      "epoch: 43, loss: 0.029067\n",
      "epoch: 43, loss: 0.113189\n",
      "epoch: 43, loss: 0.058819\n",
      "epoch: 43, loss: 0.046621\n",
      "epoch: 43, loss: 0.018125\n",
      "epoch: 43, loss: 0.050845\n",
      "epoch: 43, loss: 0.061622\n",
      "epoch: 43, loss: 0.073710\n",
      "epoch: 43, loss: 0.056270\n",
      "epoch: 43, loss: 0.057268\n",
      "epoch: 43, loss: 0.058196\n",
      "epoch: 43, loss: 0.106465\n",
      "epoch: 43, loss: 0.070079\n",
      "epoch: 43, loss: 0.085904\n",
      "epoch: 43, loss: 0.043580\n",
      "epoch: 43, loss: 0.049839\n",
      "epoch: 43, loss: 0.091941\n",
      "epoch: 43, loss: 0.037829\n",
      "epoch: 43, loss: 0.033748\n",
      "epoch: 43, loss: 0.030914\n",
      "epoch: 43, loss: 0.075663\n",
      "epoch: 43, loss: 0.097393\n",
      "epoch: 43, loss: 0.053029\n",
      "epoch: 43, loss: 0.046199\n",
      "epoch: 43, loss: 0.106288\n",
      "epoch: 43, loss: 0.066723\n",
      "epoch: 43, loss: 0.048663\n",
      "epoch: 43, loss: 0.070690\n",
      "epoch: 43, loss: 0.118813\n",
      "epoch: 44, loss: 0.106353\n",
      "epoch: 44, loss: 0.095211\n",
      "epoch: 44, loss: 0.095958\n",
      "epoch: 44, loss: 0.105804\n",
      "epoch: 44, loss: 0.123616\n",
      "epoch: 44, loss: 0.057581\n",
      "epoch: 44, loss: 0.033345\n",
      "epoch: 44, loss: 0.097433\n",
      "epoch: 44, loss: 0.125138\n",
      "epoch: 44, loss: 0.048766\n",
      "epoch: 44, loss: 0.099957\n",
      "epoch: 44, loss: 0.053170\n",
      "epoch: 44, loss: 0.104067\n",
      "epoch: 44, loss: 0.038728\n",
      "epoch: 44, loss: 0.114626\n",
      "epoch: 44, loss: 0.084419\n",
      "epoch: 44, loss: 0.098125\n",
      "epoch: 44, loss: 0.055015\n",
      "epoch: 44, loss: 0.069822\n",
      "epoch: 44, loss: 0.059351\n",
      "epoch: 44, loss: 0.046597\n",
      "epoch: 44, loss: 0.085894\n",
      "epoch: 44, loss: 0.063820\n",
      "epoch: 44, loss: 0.055311\n",
      "epoch: 44, loss: 0.032264\n",
      "epoch: 44, loss: 0.066458\n",
      "epoch: 44, loss: 0.033161\n",
      "epoch: 44, loss: 0.065554\n",
      "epoch: 44, loss: 0.099979\n",
      "epoch: 44, loss: 0.064006\n",
      "epoch: 44, loss: 0.057444\n",
      "epoch: 44, loss: 0.048784\n",
      "epoch: 44, loss: 0.048162\n",
      "epoch: 44, loss: 0.069361\n",
      "epoch: 44, loss: 0.066845\n",
      "epoch: 44, loss: 0.075334\n",
      "epoch: 44, loss: 0.022518\n",
      "epoch: 44, loss: 0.045455\n",
      "epoch: 44, loss: 0.039029\n",
      "epoch: 44, loss: 0.048455\n",
      "epoch: 44, loss: 0.044765\n",
      "epoch: 44, loss: 0.048022\n",
      "epoch: 44, loss: 0.120244\n",
      "epoch: 44, loss: 0.015982\n",
      "epoch: 44, loss: 0.078600\n",
      "epoch: 44, loss: 0.109073\n",
      "epoch: 44, loss: 0.095371\n",
      "epoch: 44, loss: 0.075632\n",
      "epoch: 44, loss: 0.016319\n",
      "epoch: 44, loss: 0.033699\n",
      "epoch: 44, loss: 0.091168\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c9de863f4121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lebedev/satellite_segmentation/learning_experiment.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, net, batch_generator, epochs, batch_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epoch_%d_interrupted\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment.train(net, batch_generator, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_34:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.optimizer.lr.assign(0.2e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
